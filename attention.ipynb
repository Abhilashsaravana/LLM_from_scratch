{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba627e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4da640",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442b74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"the\",\"sun\",\"rises\",\"in\",\"the\",\"east\"]\n",
    "model=Word2Vec([words],min_count=1,vector_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c7e5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15122044  0.21846838 -0.16200535]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['sun'])  # Example to get the vector for the word 'sun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db98943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0179,  0.0079,  0.1701],\n",
      "        [-0.1512,  0.2185, -0.1620],\n",
      "        [-0.1254,  0.2460, -0.0511],\n",
      "        [ 0.2153,  0.2991, -0.1672],\n",
      "        [-0.0179,  0.0079,  0.1701],\n",
      "        [ 0.3003, -0.3101, -0.2372]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(model.wv[words])  # Convert words to their corresponding vectors\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41aa979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([-0.0231,  0.0968,  0.0810,  0.0599, -0.0231, -0.0747])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 'sun'\n",
    "print(inputs.shape)\n",
    "scores = torch.empty(len(words))\n",
    "for i,x in enumerate(inputs):\n",
    "    scores[i] = torch.dot(query, x)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba98b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1982,  0.8297,  0.6940,  0.5130, -0.1982, -0.6403])\n",
      "tensor([0.1594, 0.1797, 0.1769, 0.1732, 0.1594, 0.1514])\n"
     ]
    }
   ],
   "source": [
    "weights = scores/torch.sum(scores)\n",
    "print(weights)\n",
    "\n",
    "weights_softmax = torch.softmax(scores, dim=0)\n",
    "print(weights_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab17524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0277,  0.0902, -0.0488])\n"
     ]
    }
   ],
   "source": [
    "context_vec2 = torch.zeros(3)\n",
    "for i, w in enumerate(weights_softmax):\n",
    "    context_vec2 += w * inputs[i]\n",
    "print(context_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36d120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0293, -0.0231, -0.0045, -0.0299,  0.0293, -0.0482],\n",
      "        [-0.0231,  0.0968,  0.0810,  0.0599, -0.0231, -0.0747],\n",
      "        [-0.0045,  0.0810,  0.0789,  0.0551, -0.0045, -0.1018],\n",
      "        [-0.0299,  0.0599,  0.0551,  0.1638, -0.0299,  0.0116],\n",
      "        [ 0.0293, -0.0231, -0.0045, -0.0299,  0.0293, -0.0482],\n",
      "        [-0.0482, -0.0747, -0.1018,  0.0116, -0.0482,  0.2426]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = torch.matmul(inputs, inputs.T)\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5ca0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1729, 0.1641, 0.1672, 0.1630, 0.1729, 0.1600],\n",
      "        [0.1594, 0.1797, 0.1769, 0.1732, 0.1594, 0.1514],\n",
      "        [0.1627, 0.1773, 0.1769, 0.1727, 0.1627, 0.1476],\n",
      "        [0.1553, 0.1699, 0.1691, 0.1885, 0.1553, 0.1619],\n",
      "        [0.1729, 0.1641, 0.1672, 0.1630, 0.1729, 0.1600],\n",
      "        [0.1582, 0.1541, 0.1499, 0.1680, 0.1582, 0.2116]])\n"
     ]
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0066da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums to 1: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sums to 1:\", attention_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ccd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0312,  0.0788, -0.0415],\n",
      "        [ 0.0277,  0.0902, -0.0488],\n",
      "        [ 0.0267,  0.0907, -0.0463],\n",
      "        [ 0.0367,  0.0873, -0.0532],\n",
      "        [ 0.0312,  0.0788, -0.0415],\n",
      "        [ 0.0519,  0.0577, -0.0571]])\n"
     ]
    }
   ],
   "source": [
    "contexts_vecs = torch.matmul(attention_weights, inputs)\n",
    "print(contexts_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b83ca",
   "metadata": {},
   "source": [
    "Simple self attention mechanism with trainable weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f957543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0179,  0.0079,  0.1701],\n",
      "        [-0.1512,  0.2185, -0.1620],\n",
      "        [-0.1254,  0.2460, -0.0511],\n",
      "        [ 0.2153,  0.2991, -0.1672],\n",
      "        [-0.0179,  0.0079,  0.1701],\n",
      "        [ 0.3003, -0.3101, -0.2372]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0752,  0.1587],\n",
      "        [-0.9577,  0.2083],\n",
      "        [-1.0922,  1.6647]], requires_grad=True) Parameter containing:\n",
      "tensor([[ 1.8339, -1.5779],\n",
      "        [ 0.0455,  0.4731],\n",
      "        [ 0.2565, -1.3649]], requires_grad=True) Parameter containing:\n",
      "tensor([[-0.0183,  1.8188],\n",
      "        [-1.9143,  0.5137],\n",
      "        [ 1.2977,  1.2557]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "w_query=torch.nn.Parameter(torch.randn(inputs.shape[1],2),requires_grad=True)  \n",
    "w_key=torch.nn.Parameter(torch.randn(inputs.shape[1],2),requires_grad=True)  \n",
    "w_value=torch.nn.Parameter(torch.randn(inputs.shape[1],2),requires_grad=True)\n",
    "print(w_key,w_value,w_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46331260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2060,  0.1852],\n",
      "        [-0.6257, -0.3662],\n",
      "        [-0.5350, -0.1660],\n",
      "        [-0.7935,  0.3353],\n",
      "        [ 0.2060,  0.1852],\n",
      "        [ 0.2803,  0.0890]], grad_fn=<MmBackward0>) tensor([[-0.1920,  0.2820],\n",
      "        [-0.0209, -0.2482],\n",
      "        [-0.1703, -0.0538],\n",
      "        [-0.1200, -0.1818],\n",
      "        [-0.1920,  0.2820],\n",
      "        [ 0.5335, -0.4118]], grad_fn=<MmBackward0>) tensor([[ 0.0112, -0.2003],\n",
      "        [-0.3089,  0.5631],\n",
      "        [-0.2320,  0.3841],\n",
      "        [ 0.3656,  0.0300],\n",
      "        [ 0.0112, -0.2003],\n",
      "        [ 0.4758, -0.2968]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query2 = torch.matmul(inputs, w_query)\n",
    "keys2 = torch.matmul(inputs, w_key)\n",
    "values2 = torch.matmul(inputs, w_value)\n",
    "print(query2,keys2,values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c944992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0127, -0.0503, -0.0450, -0.0584,  0.0127,  0.0336],\n",
      "        [ 0.0169,  0.1040,  0.1263,  0.1417,  0.0169, -0.1830],\n",
      "        [ 0.0559,  0.0524,  0.1001,  0.0944,  0.0559, -0.2171],\n",
      "        [ 0.2469, -0.0666,  0.1171,  0.0343,  0.2469, -0.5614],\n",
      "        [ 0.0127, -0.0503, -0.0450, -0.0584,  0.0127,  0.0336],\n",
      "        [-0.0287, -0.0279, -0.0525, -0.0498, -0.0287,  0.1129]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[0.1700, 0.1626, 0.1632, 0.1617, 0.1700, 0.1725],\n",
      "        [0.1638, 0.1742, 0.1770, 0.1789, 0.1638, 0.1422],\n",
      "        [0.1700, 0.1696, 0.1754, 0.1747, 0.1700, 0.1402],\n",
      "        [0.1946, 0.1559, 0.1775, 0.1674, 0.1946, 0.1099],\n",
      "        [0.1700, 0.1626, 0.1632, 0.1617, 0.1700, 0.1725],\n",
      "        [0.1646, 0.1647, 0.1619, 0.1622, 0.1646, 0.1820]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attention_scores2 = torch.matmul(query2, keys2.T)\n",
    "print(attention_scores2)\n",
    "attention_scores2norm = torch.softmax(attention_scores2/(2**0.5), dim=-1)\n",
    "print(attention_scores2norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdd303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfattention(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.w_query = torch.nn.Parameter(torch.randn(input_dim, out_dim), requires_grad=True)\n",
    "        self.w_key = torch.nn.Parameter(torch.randn(input_dim, out_dim), requires_grad=True)\n",
    "        self.w_value = torch.nn.Parameter(torch.randn(input_dim, out_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = torch.matmul(x, self.w_query)\n",
    "        keys = torch.matmul(x, self.w_key)\n",
    "        values = torch.matmul(x, self.w_value)\n",
    "\n",
    "        attention_scores = torch.matmul(queries, keys.T) \n",
    "        attention_weights = torch.softmax(attention_scores/(keys.shape[1]**0.5), dim=-1)\n",
    "\n",
    "        output = torch.matmul(attention_weights, values)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5bb8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1446, 0.0182],\n",
      "        [0.1522, 0.0161],\n",
      "        [0.1489, 0.0136],\n",
      "        [0.1517, 0.0200],\n",
      "        [0.1446, 0.0182],\n",
      "        [0.1518, 0.0351]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_attention = selfattention(input_dim=3, out_dim=2)\n",
    "output = test_attention(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e4d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfattentionv2(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.w_query = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "        self.w_key = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "        self.w_value = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        attention_scores = torch.matmul(queries, keys.T) \n",
    "        attention_weights = torch.softmax(attention_scores/(keys.shape[1]**0.5), dim=-1)\n",
    "\n",
    "        output = torch.matmul(attention_weights, values)\n",
    "        return output,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba162dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1670, 0.1665, 0.1668, 0.1668, 0.1670, 0.1659],\n",
      "        [0.1656, 0.1677, 0.1669, 0.1666, 0.1656, 0.1677],\n",
      "        [0.1659, 0.1673, 0.1668, 0.1666, 0.1659, 0.1675],\n",
      "        [0.1669, 0.1651, 0.1651, 0.1662, 0.1669, 0.1699],\n",
      "        [0.1670, 0.1665, 0.1668, 0.1668, 0.1670, 0.1659],\n",
      "        [0.1674, 0.1653, 0.1658, 0.1665, 0.1674, 0.1676]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test2 = selfattentionv2(input_dim=3, out_dim=2)\n",
    "output2,weights = test2.forward(inputs)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acdb67",
   "metadata": {},
   "source": [
    "<b>Causal Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c57ace1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(weights.shape))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c412bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1670, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1656, 0.1677, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1659, 0.1673, 0.1668, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1669, 0.1651, 0.1651, 0.1662, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1665, 0.1668, 0.1668, 0.1670, 0.0000],\n",
      "        [0.1674, 0.1653, 0.1658, 0.1665, 0.1674, 0.1676]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_weights = weights * mask\n",
    "print(masked_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d05f8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4968, 0.5032, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3318, 0.3347, 0.3335, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2516, 0.2490, 0.2489, 0.2505, 0.0000, 0.0000],\n",
      "        [0.2002, 0.1996, 0.2000, 0.1999, 0.2002, 0.0000],\n",
      "        [0.1674, 0.1653, 0.1658, 0.1665, 0.1674, 0.1676]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_weights.sum(dim=-1, keepdim=True)\n",
    "normalized_masked_weights = masked_weights / row_sums \n",
    "print(normalized_masked_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53314e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1670,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1656, 0.1677,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1659, 0.1673, 0.1668,   -inf,   -inf,   -inf],\n",
      "        [0.1669, 0.1651, 0.1651, 0.1662,   -inf,   -inf],\n",
      "        [0.1670, 0.1665, 0.1668, 0.1668, 0.1670,   -inf],\n",
      "        [0.1674, 0.1653, 0.1658, 0.1665, 0.1674, 0.1676]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(weights.shape), diagonal=1)\n",
    "masked=weights.masked_fill(mask.bool(), float('-inf'))\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1dbba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4996, 0.5004, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3332, 0.3335, 0.3334, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2502, 0.2499, 0.2499, 0.2501, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000],\n",
      "        [0.1668, 0.1665, 0.1666, 0.1666, 0.1668, 0.1668]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.softmax(masked/keys2.shape[-1]**0.5, dim=1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d5889",
   "metadata": {},
   "source": [
    "<b>Attention weights with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb4aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0008, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6667, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5004, 0.4998, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(p=0.5)\n",
    "dropped_weights = dropout(weights)\n",
    "print(dropped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398f6c4",
   "metadata": {},
   "source": [
    "<b>Causal Attention Mechanism Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b451b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class causalattention(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim,context_len,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.w_query = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "        self.w_key = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "        self.w_value = torch.nn.Linear(input_dim, out_dim,bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_len, context_len), diagonal=1))\n",
    "    def forward(self, x):\n",
    "        b,num_tokens,input_dim = x.shape\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(1,2))\n",
    "        attention_scores=attention_scores.masked_fill(self.mask.bool()[:num_tokens,:num_tokens], float('-inf')) \n",
    "        attention_weights = torch.softmax(attention_scores/(keys.shape[1]**0.5), dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        output = torch.matmul(attention_weights, values)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ee3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0055,  0.2110],\n",
      "         [-0.0492,  0.1841],\n",
      "         [-0.0018,  0.0584],\n",
      "         [-0.0016,  0.0483]],\n",
      "\n",
      "        [[-0.0294, -0.0246],\n",
      "         [ 0.0254,  0.1736],\n",
      "         [ 0.0168,  0.1152],\n",
      "         [ 0.0125,  0.0858],\n",
      "         [-0.0437,  0.0797],\n",
      "         [-0.0355, -0.0025]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs,inputs),dim=0)  # Create a batch of 2 identical sequences\n",
    "print(batch.shape)\n",
    "test3 = causalattention(input_dim=3, out_dim=2,context_len=6,dropout=0.5)\n",
    "contexts_vecs = test3.forward(batch)\n",
    "print(contexts_vecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f13f15",
   "metadata": {},
   "source": [
    "<b> Multi Head attention mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4124f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiheadattentionv1(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, num_heads, context_len, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_heads = torch.nn.ModuleList([\n",
    "            causalattention(input_dim, out_dim, context_len, dropout, qkv_bias) \n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.attention_heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33734ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0155, -0.0989, -0.0257,  0.0369],\n",
      "         [-0.0426, -0.0455, -0.0035, -0.0393],\n",
      "         [ 0.0407, -0.0665, -0.0009, -0.0094],\n",
      "         [ 0.0250, -0.1343, -0.0020, -0.0236],\n",
      "         [ 0.0415, -0.0551,  0.0331, -0.0256]],\n",
      "\n",
      "        [[ 0.1580, -0.0613,  0.0000,  0.0000],\n",
      "         [-0.0637, -0.0681, -0.0257,  0.0369],\n",
      "         [ 0.0119, -0.1339, -0.0183,  0.0120],\n",
      "         [-0.0095, -0.1013, -0.0035, -0.0390],\n",
      "         [ 0.0250, -0.1343, -0.0102,  0.0147],\n",
      "         [ 0.0049, -0.0333,  0.0029,  0.0358]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test4 = Multiheadattentionv1(input_dim=3, out_dim=2, num_heads=2, context_len=6, dropout=0.5)\n",
    "contexts_vecs_multihead = test4.forward(batch)\n",
    "print(contexts_vecs_multihead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeac7af",
   "metadata": {},
   "source": [
    "<b>Multi head attention with weight splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db2b4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiheadattentionv2(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, num_heads, context_len, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert out_dim % num_heads == 0, \"out_dim must be divisible by num_heads\"\n",
    "        self.out_dim = out_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = out_dim // num_heads\n",
    "        self.w_query = torch.nn.Linear(input_dim, out_dim, bias=qkv_bias)\n",
    "        self.w_key = torch.nn.Linear(input_dim, out_dim, bias=qkv_bias)\n",
    "        self.w_value = torch.nn.Linear(input_dim, out_dim, bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_len, context_len), diagonal=1))\n",
    "        self.out=torch.nn.Linear(out_dim,out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, input_dim = x.shape\n",
    "        \n",
    "        # Split and reshape for multi-head attention\n",
    "        queries = self.w_query(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = self.w_key(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = self.w_value(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        \n",
    "        attention_scores = torch.matmul(queries, keys.transpose(2, 3))\n",
    "        attention_scores = attention_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores/keys.shape[-1]**0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        output = torch.matmul(attention_weights, values).transpose(1, 2).contiguous().view(b, num_tokens, self.out_dim)\n",
    "        output=self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10217611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0089,  0.0039,  0.0851,  0.1502, -0.1550, -0.1186],\n",
      "        [ 0.1058, -0.0568, -0.0158,  0.0961, -0.1254, -0.0656],\n",
      "        [-0.1381, -0.1575,  0.1219,  0.0845,  0.1126,  0.0127],\n",
      "        [-0.0756,  0.1092, -0.0810, -0.0303,  0.0479,  0.0165],\n",
      "        [-0.0089,  0.0039,  0.0851,  0.1502, -0.1550, -0.1186],\n",
      "        [ 0.1076,  0.1495, -0.0836, -0.0627,  0.1230, -0.0256]])\n",
      "torch.Size([2, 6, 6])\n",
      "tensor([[[ 0.1273, -0.1444, -0.3163,  0.0027,  0.0074,  0.0082],\n",
      "         [ 0.1273, -0.1444, -0.3163,  0.0027,  0.0074,  0.0082],\n",
      "         [ 0.1270, -0.1311, -0.2984,  0.0088, -0.0030,  0.0049],\n",
      "         [ 0.1215, -0.1003, -0.3155,  0.0162,  0.0383,  0.0058],\n",
      "         [ 0.1428, -0.1302, -0.3212, -0.0088,  0.0352,  0.0240],\n",
      "         [ 0.1483, -0.1352, -0.3106, -0.0075,  0.0210,  0.0213]],\n",
      "\n",
      "        [[ 0.1273, -0.1444, -0.3163,  0.0027,  0.0074,  0.0082],\n",
      "         [ 0.1308, -0.1435, -0.3236,  0.0080,  0.0105,  0.0022],\n",
      "         [ 0.1135, -0.0763, -0.3046,  0.0431,  0.0349, -0.0150],\n",
      "         [ 0.1321, -0.1209, -0.3109,  0.0035,  0.0158,  0.0083],\n",
      "         [ 0.1116, -0.1279, -0.3007,  0.0265, -0.0008, -0.0058],\n",
      "         [ 0.1110, -0.1219, -0.2924,  0.0263, -0.0068, -0.0067]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "words=[\"the\",\"sun\",\"rises\",\"in\",\"the\",\"east\"]\n",
    "model=Word2Vec([words],min_count=1,vector_size=6)\n",
    "inputs = torch.tensor(model.wv[words])  # Convert words to their corresponding vectors\n",
    "print(inputs)\n",
    "batch = torch.stack((inputs,inputs),dim=0)  # Create a batch of 2 identical sequences\n",
    "print(batch.shape)\n",
    "test4 = Multiheadattentionv2(input_dim=6, out_dim=6, num_heads=2, context_len=6, dropout=0.5)\n",
    "contexts_vecs_multihead = test4.forward(batch)\n",
    "print(contexts_vecs_multihead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5527ddc",
   "metadata": {},
   "source": [
    "<b>Implementing Dummy GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "094881fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M={\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_len\": 1024,\n",
    "    \"n_embd\": 768,\n",
    "    \"n_layer\": 12,\n",
    "    \"n_head\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "461faeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class DummyGPTModel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embedding = torch.nn.Embedding(config['vocab_size'], config['n_embd'])\n",
    "        self.position_embedding = torch.nn.Embedding(config['context_len'], config['n_embd'])\n",
    "        self.dropout = torch.nn.Dropout(config['dropout'])\n",
    "        \n",
    "        #Placeholder for the actual transformer blocks\n",
    "        self.trf = torch.nn.Sequential(\n",
    "            *[DummyTransformer(config) for _ in range(config['n_layer'])])\n",
    "        \n",
    "        # Final layer norm\n",
    "        self.final_norm = DummyLayerNorm(config['n_embd'])\n",
    "        self.head = torch.nn.Linear(config['n_embd'], config['vocab_size'], bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, idx):\n",
    "        b, t = idx.shape\n",
    "        token_embeddings = self.token_embedding(idx)\n",
    "        position_embeddings = self.position_embedding(torch.arange(t, device=idx.device))\n",
    "        \n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.trf(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.head(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class DummyTransformer(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "class DummyLayerNorm(torch.nn.Module):\n",
    "    def __init__(self,shape,eps=1e-5):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49ad57",
   "metadata": {},
   "source": [
    "<b> Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f558296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4252, 16736,   287,   262],\n",
      "        [  464,  4252,  5621,   287,   262]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch=[]\n",
    "txt1 = \"The sun rises in the\"\n",
    "txt2 = \"The sun sets in the\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbce10a",
   "metadata": {},
   "source": [
    "<b>Instance of DummyGPTModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a92944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 50257])\n",
      "tensor([[[ 0.5209,  0.5520, -0.1626,  ..., -0.6756,  0.4891,  1.0015],\n",
      "         [ 0.2441,  1.2358,  0.7340,  ...,  0.8618,  0.6503,  0.6837],\n",
      "         [-0.1495,  0.3894, -0.2040,  ...,  0.3658, -0.6975,  0.0046],\n",
      "         [-0.4361,  2.2998, -0.8146,  ...,  1.0815, -0.0610,  0.4576],\n",
      "         [-0.6581, -0.4606,  0.6273,  ...,  0.6359, -1.1219, -0.1483]],\n",
      "\n",
      "        [[ 0.6502,  0.6544, -0.4624,  ..., -0.6154,  0.2181,  1.1435],\n",
      "         [ 0.4852,  1.2206, -0.0328,  ...,  0.7643,  0.6751,  0.7432],\n",
      "         [ 0.4855,  0.2990, -0.0415,  ..., -0.3032,  0.9354,  0.3412],\n",
      "         [-0.1921,  1.6800, -0.7408,  ...,  0.7503,  0.0276,  0.4491],\n",
      "         [-0.4396, -0.8658,  0.2206,  ...,  0.7252, -1.3121,  0.0530]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93ddef",
   "metadata": {},
   "source": [
    "<b> Layer Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ce29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self, n_embd, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(n_embd))\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(n_embd))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        variance = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x_normalized = (x - mean) / torch.sqrt(variance + self.eps)\n",
    "        return self.gamma * x_normalized + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "657cb643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.1467e-08],\n",
      "        [6.9539e-08]], grad_fn=<MeanBackward1>)\n",
      "tensor([[1.1999],\n",
      "        [1.1999]], grad_fn=<VarBackward0>)\n",
      "tensor([[ 0.3324,  0.8349, -0.2272,  0.0529, -2.0204,  1.0276],\n",
      "        [-1.4542, -0.9964,  1.2767,  0.3657,  1.0374, -0.2291]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch = torch.randn(2, 6)\n",
    "ln = LayerNorm(n_embd=6)\n",
    "output = ln.forward(batch)\n",
    "mean = output.mean(dim=-1,keepdim=True)\n",
    "var = output.var(dim=-1,keepdim=True)\n",
    "print(mean)\n",
    "print(var)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312657d3",
   "metadata": {},
   "source": [
    "<b> GELU Activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df3b1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class GELU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi)) * (x + 0.044715 * (x ** 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19201091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(cfg['n_embd'], cfg['n_embd']*4),\n",
    "            GELU(),\n",
    "            torch.nn.Linear(cfg['n_embd']*4, cfg['n_embd']),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4435666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "batch = torch.randn(2, 6, 768)\n",
    "output = ffn.forward(batch)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd581f37",
   "metadata": {},
   "source": [
    "<b>Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "609c70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer_block(torch.nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(cfg['n_embd'])\n",
    "        self.attn = Multiheadattentionv2(cfg['n_embd'], cfg['n_embd'], cfg['n_head'], cfg['context_len'], cfg['dropout'], cfg['qkv_bias'])\n",
    "        self.ln2 = LayerNorm(cfg['n_embd'])\n",
    "        self.ffn = FeedForward(cfg)\n",
    "        self.dropout = torch.nn.Dropout(cfg['dropout'])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "169e991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 768])\n",
      "torch.Size([2, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2, 6, 768)\n",
    "block = transformer_block(GPT_CONFIG_124M)\n",
    "output = block.forward(input)\n",
    "print(input.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de947433",
   "metadata": {},
   "source": [
    "<b> Implementing GPT from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6eac9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M={\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_len\": 256,\n",
    "    \"n_embd\": 768,\n",
    "    \"n_layer\": 12,\n",
    "    \"n_head\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15369aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class GPTModel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embedding = torch.nn.Embedding(config['vocab_size'], config['n_embd'])\n",
    "        self.position_embedding = torch.nn.Embedding(config['context_len'], config['n_embd'])\n",
    "        self.dropout = torch.nn.Dropout(config['dropout'])\n",
    "        \n",
    "        self.trf = torch.nn.Sequential(\n",
    "            *[transformer_block(config) for _ in range(config['n_layer'])])\n",
    "\n",
    "        self.final_norm = LayerNorm(config['n_embd'])\n",
    "        self.head = torch.nn.Linear(config['n_embd'], config['vocab_size'], bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, idx):\n",
    "        b, t = idx.shape\n",
    "        token_embeddings = self.token_embedding(idx)\n",
    "        position_embeddings = self.position_embedding(torch.arange(t, device=idx.device))\n",
    "        \n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.trf(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.head(x)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f0a6c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[  464,  4252, 16736,   287],\n",
      "        [  464,  4252,  5621,   287]])\n",
      "torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.2051,  0.8490, -0.1744,  ...,  0.2625, -0.0825, -0.0359],\n",
      "         [-0.8707,  0.4461, -0.6750,  ...,  0.5378, -1.0888,  0.0507],\n",
      "         [ 0.4990, -0.3784,  0.0500,  ..., -0.2422, -0.0112,  0.3251],\n",
      "         [-0.4065, -0.0602,  0.2662,  ...,  1.1062, -0.1149,  0.4700]],\n",
      "\n",
      "        [[-0.3536,  0.4417,  0.5092,  ..., -0.2516, -0.2595, -0.3223],\n",
      "         [-0.3141,  0.5631, -0.3046,  ...,  0.6937, -1.0243, -0.0206],\n",
      "         [ 0.7400,  1.0240,  0.6014,  ...,  0.2021,  0.4832, -0.6535],\n",
      "         [-0.1725, -0.1836,  0.2340,  ...,  1.0573,  0.3967,  0.9564]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch=[]\n",
    "txt1 = \"The sun rises in\"\n",
    "txt2 = \"The sun sets in\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "print(batch.shape)\n",
    "print(batch)\n",
    "output = model(batch)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a43533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "total_param = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7033bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters without the head: 123,822,336\n"
     ]
    }
   ],
   "source": [
    "total_param_2=total_param-sum(p.numel() for p in model.head.parameters())\n",
    "print(f\"Total parameters without the head: {total_param_2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052e622",
   "metadata": {},
   "source": [
    "<b> Generating text from output tokens:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab6fb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_txt(model,input, max_new_tokens,context_len):\n",
    "    for i in range(max_new_tokens):\n",
    "        input_cond = input[:,-context_len:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probs,dim=-1,keepdim=True)\n",
    "        input = torch.cat((input, next_token), dim=1)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "836d344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4252, 16736,   287]])\n"
     ]
    }
   ],
   "source": [
    "input = \"The sun rises in\"\n",
    "encoded_input = torch.tensor(tokenizer.encode(input)).unsqueeze(0) \n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "344e356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4252, 16736,   287, 17276, 23382,  2390,  6997, 19020, 43417]])\n",
      "The sun rises in locate NotreAM Ms FactDomin\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output_tokens = generate_output_txt(model, encoded_input, max_new_tokens=6, context_len=GPT_CONFIG_124M['context_len'])\n",
    "print(output_tokens)\n",
    "print(tokenizer.decode(output_tokens[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ecab6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun rises in locate NotreAM Ms FactDomin\n"
     ]
    }
   ],
   "source": [
    "def text_to_tokens(text,tokenizer):\n",
    "    return torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
    "def tokens_to_text(tokens,tokenizer):\n",
    "    return tokenizer.decode((tokens.squeeze(0)).tolist())\n",
    "\n",
    "ex = \"The sun rises in\"\n",
    "toeken_ids=generate_output_txt(model,text_to_tokens(ex,tokenizer), max_new_tokens=6,context_len=GPT_CONFIG_124M['context_len'])\n",
    "print(tokens_to_text(toeken_ids,tokenizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ecc08e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n",
      "tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "inputs = text_to_tokens(\"every effort moves\",tokenizer)\n",
    "inputs = torch.cat([inputs, text_to_tokens(\"I really like\",tokenizer)])\n",
    "print(inputs)\n",
    "target = torch.tensor([[3626,6100,345],\n",
    "                       [1107,588,11311]])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b59df84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31758, 49756,  4222],\n",
      "        [46079, 38582, 36046]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probabs = torch.softmax(logits, dim=-1)\n",
    "output = torch.argmax(probabs,dim=-1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b5dbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  effort moves you\n",
      "Output: をhirt Please\n"
     ]
    }
   ],
   "source": [
    "print(\"Target:\",tokens_to_text(target[0],tokenizer))\n",
    "print(\"Output:\",tokens_to_text(output[0],tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372b000",
   "metadata": {},
   "source": [
    "<b> Cross Entropy Loss :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69596632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.4117e-06, 2.3470e-05, 2.4542e-05])\n",
      "tensor([5.2540e-05, 7.6158e-06, 2.7658e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0 \n",
    "target_1 = probabs[text_idx,[0,1,2],target[text_idx]]\n",
    "print(target_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_2 = probabs[text_idx,[0,1,2],target[text_idx]]\n",
    "print(target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57840d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.6859, -10.6598, -10.6151,  -9.8539, -11.7853, -10.4956])\n"
     ]
    }
   ],
   "source": [
    "#Log of all token probability\n",
    "log_probas  = torch.log(torch.cat((target_1,target_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4993733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8493)\n"
     ]
    }
   ],
   "source": [
    "#Calculate average probability\n",
    "avg_log_prob = torch.mean(log_probas)\n",
    "print(avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0948ec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8493)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_prob = -avg_log_prob\n",
    "print(neg_avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8466c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50257]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#Using PyTorch Cross Entropy Loss\n",
    "logits_flat = logits.flatten(0,1)\n",
    "target = target.flatten()\n",
    "print(logits_flat.shape,target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b831eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8493)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa6b23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7062177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5989d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "total_chars = len(text)\n",
    "total_tokens = len(tokenizer.encode(text))\n",
    "\n",
    "print(total_chars)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be05740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, context_len,stride):\n",
    "        self.inputs = []\n",
    "        self.targets =[]\n",
    "        \n",
    "        tokens = tokenizer.encode(text)\n",
    "        \n",
    "        for i in range(0, len(tokens) - context_len, stride):\n",
    "            input_ids = tokens[i:i + context_len]\n",
    "            target_ids = tokens[i + 1:i + context_len + 1]\n",
    "            self.inputs.append(torch.tensor(input_ids))\n",
    "            self.targets.append(torch.tensor(target_ids))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "    \n",
    "def create_dataloader(text,batch_size=4,context_len =256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(text, tokenizer, context_len,stride)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b05f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * len(text))\n",
    "train_text = text[:train_size]\n",
    "val_text = text[train_size:]\n",
    "\n",
    "train_dataloader = create_dataloader(train_text,batch_size=2,context_len =GPT_CONFIG_124M[\"context_len\"],stride=GPT_CONFIG_124M[\"context_len\"],shuffle=True,drop_last=True,num_workers=0)\n",
    "val_dataloader = create_dataloader(val_text,batch_size=2,context_len =GPT_CONFIG_124M[\"context_len\"],stride=GPT_CONFIG_124M[\"context_len\"],shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae5c81ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "for xb,yb in train_dataloader:\n",
    "    print(xb.shape,yb.shape)\n",
    "\n",
    "\n",
    "for xb,yb in val_dataloader:\n",
    "    print(xb.shape,yb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2da3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(input_batch,output_batch,model,device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    output_batch = output_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),output_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(dataloader,model,device,num_batches=None):\n",
    "    loss = 0\n",
    "    if len(dataloader)==0:\n",
    "        return 'nan'\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(dataloader))\n",
    "    for i,(xb,yb) in enumerate(dataloader):\n",
    "        if i>=num_batches:\n",
    "            break\n",
    "        loss += calc_loss(xb,yb,model,device).item()\n",
    "    return loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97e5797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.9785, Val loss: 11.0072\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_dataloader,model,device,num_batches=10)\n",
    "    val_loss = calc_loss_loader(val_dataloader,model,device,num_batches=10)\n",
    "print(f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e77fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(model,train_dataloader,val_dataloader,optimizer,device,epochs=3,eval_freq=200,eval_iter=10,start_context=0,tokenizer=None):\n",
    "    train_losses,val_losses,track_tokens_seen=[],[],[]\n",
    "    tokens_seen,global_step=0,-1\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i,(xb,yb) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss(xb,yb,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += xb.numel()\n",
    "            global_step += 1\n",
    "            if (global_step) % eval_freq == 0:\n",
    "                train_loss,val_loss = eval_simple(model,train_dataloader,val_dataloader,device,eval_batches=eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {i+1}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "                model.train()\n",
    "        \n",
    "        generate_text(model,tokenizer,device,start_context)\n",
    "    \n",
    "    return train_losses,val_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "715ed524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_simple(model,train_dataloader,val_dataloader,device,eval_batches=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_dataloader,model,device,num_batches=eval_batches)\n",
    "        val_loss = calc_loss_loader(val_dataloader,model,device,num_batches=eval_batches)\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6eec8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,device, start_text):\n",
    "    model.eval()\n",
    "    context = model.position_embedding.weight.shape[0]\n",
    "    encoded_input = text_to_tokens(start_text,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_tokens = generate_output_txt(model, encoded_input, max_new_tokens=50, context_len=context)\n",
    "    decoded_text = tokens_to_text(output_tokens[0],tokenizer)\n",
    "    print(decoded_text.replace('\\n',' '))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83454d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1, Train loss: 9.7442, Val loss: 10.0076\n",
      "Epoch 1, Step 6, Train loss: 8.1409, Val loss: 8.3915\n",
      "Every effort moves you.                                                 \n",
      "Epoch 2, Step 2, Train loss: 6.7276, Val loss: 7.1240\n",
      "Epoch 2, Step 7, Train loss: 6.0883, Val loss: 6.6707\n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,, and,, and, and,,,, and, and,, and, and,, and,, and, and, and,\n",
      "Epoch 3, Step 3, Train loss: 13.7420, Val loss: 14.5328\n",
      "Epoch 3, Step 8, Train loss: 5.5481, Val loss: 6.4492\n",
      "Every effort moves you of the                                                \n",
      "Epoch 4, Step 4, Train loss: 5.1153, Val loss: 6.4993\n",
      "Epoch 4, Step 9, Train loss: 4.6254, Val loss: 6.3750\n",
      "Every effort moves you of the fact--and I had beenisburn, I had beenisburn. Gisburn, and he had been had been one of the wasburn's \" to see of the fact--and of the fact--his, and in the\n",
      "Epoch 5, Step 5, Train loss: 4.3075, Val loss: 6.2990\n",
      "Every effort moves you of the first, and I felt, I felt, and in the fact--and to see it, and he had been his own, and, and in the Riv to see it--and I had been his own--and, and in his\n",
      "Epoch 6, Step 1, Train loss: 3.5956, Val loss: 6.1891\n",
      "Epoch 6, Step 6, Train loss: 3.5357, Val loss: 6.2509\n",
      "Every effort moves you of the picture.                                              \n",
      "Epoch 7, Step 2, Train loss: 2.8886, Val loss: 6.2532\n",
      "Epoch 7, Step 7, Train loss: 2.2333, Val loss: 6.2759\n",
      "Every effort moves you of the him, and I felt able to have been too a little of a little: \" work, and went on a little-table, and, on the last-c.             \n",
      "Epoch 8, Step 3, Train loss: 2.0531, Val loss: 6.3015\n",
      "Epoch 8, Step 8, Train loss: 1.6527, Val loss: 6.2451\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisburn, I felt to see a smile, on the same, as his pictures--the he had been the \"There were, and in\n",
      "Epoch 9, Step 4, Train loss: 1.3729, Val loss: 6.3165\n",
      "Epoch 9, Step 9, Train loss: 0.9680, Val loss: 6.3411\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and muddling; then I looked at the donkey again. I saw that, and down the room, and I\n",
      "Epoch 10, Step 5, Train loss: 0.7677, Val loss: 6.4178\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton, and muddling; then I looked at the donkey again. I had the donkey. \"There were days when I\n",
      "Training completed in 0.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004,weight_decay=1e-1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_loss,val_loss,tokens_seen = train_simple(model,train_dataloader,val_dataloader,optimizer,device,epochs=num_epochs,eval_freq=5,eval_iter=5,start_context=\"Every effort moves you\",tokenizer=tokenizer)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Training completed in {execution_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "807726ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_txt(model,input, max_new_tokens,context_len,temperature=0.0,top_k=None,eos_token=None):\n",
    "    for i in range(max_new_tokens):\n",
    "        input_cond = input[:,-context_len:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            top_k_values, _ = torch.topk(logits, top_k)\n",
    "            min_top_k = top_k_values[:, -1]\n",
    "            logits = torch.where(logits < min_top_k, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "    \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_token = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "\n",
    "        if next_token == eos_token:\n",
    "            break\n",
    "        \n",
    "        input = torch.cat((input, next_token), dim=1)\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58e2fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun rises in spite she, and I didn Mrs. Gisburn--I wish Sev\n"
     ]
    }
   ],
   "source": [
    "model=model.to(\"cpu\")\n",
    "tokens = generate_output_txt(model,text_to_tokens(\"The sun rises in\",tokenizer), max_new_tokens=15,context_len=GPT_CONFIG_124M['context_len'],temperature=1.4,top_k=25)\n",
    "print(tokens_to_text(tokens,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3db88bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"gpt_124M_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6bc256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (trf): Sequential(\n",
       "    (0): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"gpt_124M_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e660ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004,weight_decay=1e-1)\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),}, \"gpt_124M_model_with_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5fbbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"gpt_124M_model_with_optimizer.pth\")['model_state_dict'])\n",
    "optimizer.load_state_dict(torch.load(\"gpt_124M_model_with_optimizer.pth\")['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ab93d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b95f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ./gpt2_models\\124M\\checkpoint\n",
      "File already exists and is up-to-date: ./gpt2_models\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ./gpt2_models\\124M\\hparams.json\n",
      "File already exists and is up-to-date: ./gpt2_models\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ./gpt2_models\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: ./gpt2_models\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ./gpt2_models\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings,params=download_and_load_gpt2(model_size=\"124M\",models_dir=\"./gpt2_models\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acfe0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(settings)\n",
    "print(params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4be65c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (trf): Sequential(\n",
       "    (0): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG=GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update({\n",
    "    \"context_len\": settings['n_ctx'],\n",
    "    \"qkv_bias\": True\n",
    "})\n",
    "gpt_new = GPTModel(NEW_CONFIG)\n",
    "gpt_new.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3419defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left,right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(\"Shapes do not match for assignment.\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b2ff344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def load_params_to_model(gpt_new,params):\n",
    "    gpt_new.position_embedding.weight=assign(gpt_new.position_embedding.weight,params['wpe'])\n",
    "    gpt_new.token_embedding.weight=assign(gpt_new.token_embedding.weight,params['wte'])\n",
    "    for i in range(len(params[\"blocks\"])):\n",
    "        w_q,w_k,w_v = np.split(params[\"blocks\"][i][\"attn\"]['c_attn']['w'],3,axis=-1)\n",
    "        gpt_new.trf[i].attn.w_query.weight=assign(gpt_new.trf[i].attn.w_query.weight,w_q.T)\n",
    "        gpt_new.trf[i].attn.w_key.weight=assign(gpt_new.trf[i].attn.w_key.weight,w_k.T)\n",
    "        gpt_new.trf[i].attn.w_value.weight=assign(gpt_new.trf[i].attn.w_value.weight,w_v.T)\n",
    "        \n",
    "        b_q,b_k,b_v = np.split(params[\"blocks\"][i][\"attn\"]['c_attn']['b'],3,axis=-1)\n",
    "        gpt_new.trf[i].attn.w_query.bias=assign(gpt_new.trf[i].attn.w_query.bias,b_q)\n",
    "        gpt_new.trf[i].attn.w_key.bias=assign(gpt_new.trf[i].attn.w_key.bias,b_k)\n",
    "        gpt_new.trf[i].attn.w_value.bias=assign(gpt_new.trf[i].attn.w_value.bias,b_v)\n",
    "        \n",
    "        gpt_new.trf[i].attn.out.weight=assign(gpt_new.trf[i].attn.out.weight,params[\"blocks\"][i][\"attn\"]['c_proj']['w'].T)\n",
    "        gpt_new.trf[i].attn.out.bias=assign(gpt_new.trf[i].attn.out.bias,params[\"blocks\"][i][\"attn\"]['c_proj']['b'])\n",
    "        \n",
    "        gpt_new.trf[i].ffn.layers[0].weight=assign(gpt_new.trf[i].ffn.layers[0].weight,params[\"blocks\"][i]['mlp']['c_fc']['w'].T)\n",
    "        gpt_new.trf[i].ffn.layers[0].bias=assign(gpt_new.trf[i].ffn.layers[0].bias,params[\"blocks\"][i]['mlp']['c_fc']['b'])\n",
    "        gpt_new.trf[i].ffn.layers[2].weight=assign(gpt_new.trf[i].ffn.layers[2].weight,params[\"blocks\"][i]['mlp']['c_proj']['w'].T)\n",
    "        gpt_new.trf[i].ffn.layers[2].bias=assign(gpt_new.trf[i].ffn.layers[2].bias,params[\"blocks\"][i]['mlp']['c_proj']['b'])\n",
    "        \n",
    "        gpt_new.trf[i].ln1.gamma=assign(gpt_new.trf[i].ln1.gamma,params[\"blocks\"][i]['ln_1']['g'])\n",
    "        gpt_new.trf[i].ln1.beta=assign(gpt_new.trf[i].ln1.beta,params[\"blocks\"][i]['ln_1']['b'])\n",
    "        gpt_new.trf[i].ln2.gamma=assign(gpt_new.trf[i].ln2.gamma,params[\"blocks\"][i]['ln_2']['g'])\n",
    "        gpt_new.trf[i].ln2.beta=assign(gpt_new.trf[i].ln2.beta,params[\"blocks\"][i]['ln_2']['b'])\n",
    "    \n",
    "    gpt_new.final_norm.gamma=assign(gpt_new.final_norm.gamma,params['g'])\n",
    "    gpt_new.final_norm.beta=assign(gpt_new.final_norm.beta,params['b'])\n",
    "    gpt_new.head.weight=assign(gpt_new.head.weight,params['wte'])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8ff89e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (trf): Sequential(\n",
       "    (0): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_params_to_model(gpt_new,params)\n",
    "gpt_new.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d682e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe for banana bread and bread loaves - Baked\n",
      "Ingredients: 5 cups of bread for about 5-8 servings (use 3 tablespoon bread flour to work them in different order of texture), 3 cups (30 gram jar) whole milk milk cheese or 2 teaspoons ground julienned green onion powder Directions: Take two baggies from a caddy you could place in a refrigerator. Mix thoroughly but avoid being mush on the top. Cut your slices and transfer this baggies around your loaves. Place back on lightly floured baking sheets in shallow bowl (about 1.5-1 cm). Preheat grill with 2 inches of space. Roll loaves approximately 2-3 cm. on the middle-panel (2 cm or 6 x 12 mm) from floor(s) of the oven so that they appear on an oven face. Repeat this process (approximately 3½ days each). Bake loaves in 3.5 to 5 cm square space in a 35 gr circle, rotating 90 degrees every\n"
     ]
    }
   ],
   "source": [
    "gpt_new.to(\"cpu\")\n",
    "tokens = generate_output_txt(gpt_new,text_to_tokens(\"Recipe for banana bread\",tokenizer), max_new_tokens=200,context_len=NEW_CONFIG['context_len'],temperature=1.5,top_k=50)\n",
    "print(tokens_to_text(tokens,tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f6b76",
   "metadata": {},
   "source": [
    "<b> Finetuning for email classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3589bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b24f9211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def balanced_dataset(df):\n",
    "    spam_df = df[df['Label'] == 'spam']\n",
    "    ham_df = df[df['Label'] == 'ham']\n",
    "    \n",
    "    min_size = min(len(spam_df), len(ham_df))\n",
    "    \n",
    "    spam_sampled = spam_df.sample(n=min_size, random_state=42)\n",
    "    ham_sampled = ham_df.sample(n=min_size, random_state=42)\n",
    "    \n",
    "    balanced_df = pd.concat([spam_sampled, ham_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=['Label', 'Text'])\n",
    "balanced_dataset = balanced_dataset(df)\n",
    "print(balanced_dataset['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b3b23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_ratio,validation_ratio):\n",
    "    shuffled_df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    total_size = len(shuffled_df)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * validation_ratio)\n",
    "    \n",
    "    train_df = shuffled_df.iloc[:train_size]\n",
    "    val_df = shuffled_df.iloc[train_size:train_size + val_size]\n",
    "    test_df = shuffled_df.iloc[train_size + val_size:]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = random_split(balanced_dataset, train_ratio=0.7, validation_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2bc441a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1045, Validation size: 149, Test size: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6495f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_spam.csv\", index=False)\n",
    "val_df.to_csv(\"val_spam.csv\", index=False)\n",
    "test_df.to_csv(\"test_spam.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f6cfa",
   "metadata": {},
   "source": [
    "<b> Creating Dataloaders :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "507224be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class dataset_spam(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None,pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.text = [tokenizer.encode(text) for text in self.data['Text']]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self.longest_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.text= [t[:max_length] for t in self.text]\n",
    "        self.text = [t + [pad_token_id] * (self.max_length - len(t)) for t in self.text]\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.text[idx]), torch.tensor(self.data.iloc[idx]['Label'])\n",
    "\n",
    "\n",
    "    def longest_length(self):\n",
    "        return max(len(t) for t in self.text)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5500c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "137\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset_spam(\"train_spam.csv\",tokenizer,max_length=None)\n",
    "print(train_dataset.max_length)\n",
    "val_dataset = dataset_spam(\"val_spam.csv\",tokenizer,max_length=train_dataset.max_length)\n",
    "test_dataset = dataset_spam(\"test_spam.csv\",tokenizer,max_length=train_dataset.max_length)\n",
    "print(val_dataset.max_length)\n",
    "print(test_dataset.max_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ecae97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=8,shuffle=True,num_workers=0,drop_last=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=8,shuffle=False,num_workers=0,drop_last=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=8,shuffle=False,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5b2a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "18\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c838715",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "646bea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (trf): Sequential(\n",
       "    (0): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): transformer_block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Multiheadattentionv2(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = 2\n",
    "model.head=torch.nn.Linear(GPT_CONFIG_124M['n_embd'], classes)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1fffa700",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c70a96be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6492, -0.3348],\n",
      "         [-0.1930, -1.0469],\n",
      "         [-0.1057,  0.0393],\n",
      "         [ 0.9449, -0.1363],\n",
      "         [-0.3234,  0.0913],\n",
      "         [ 0.7953,  0.1310],\n",
      "         [ 0.1208, -0.0877],\n",
      "         [ 0.2550, -1.4186],\n",
      "         [-0.1638, -0.3852],\n",
      "         [-0.7602,  0.0915],\n",
      "         [ 0.3936, -0.2983],\n",
      "         [-0.8683, -0.2277],\n",
      "         [ 0.0757, -0.8978]]])\n",
      "torch.Size([1, 13, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(torch.tensor(tokenizer.encode(\"Free entry in 2 a wkly comp to win FA Cup\")).unsqueeze(0))\n",
    "\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
